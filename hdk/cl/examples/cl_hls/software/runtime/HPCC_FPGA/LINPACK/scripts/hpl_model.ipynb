{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bitcd2879d8e76b42359b76705ca2aa7ea1",
   "display_name": "Python 3.6.8 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime of the lu block in seconds\n",
    "def lu_block(bsize, sbsize, f_kernel, f_channel=156e6, f_mem=300e6):\n",
    "    t_total = 0\n",
    "    #load block from global memory to local memory buffer\n",
    "    t_total += (bsize * bsize / sbsize) / min(f_mem, f_kernel)\n",
    "    # total time needed for updating LU sub-blocks plus latency of non-pipelined logic\n",
    "    t_total += (bsize * (sbsize + 100)) / f_kernel\n",
    "    # total time needed to update all sub-blocks\n",
    "    t_total += ((bsize - sbsize) * (bsize / sbsize) * bsize / sbsize / 2)/ f_kernel\n",
    "    # total time needed to send rows and columns to network kernel\n",
    "    t_total += (bsize * sbsize / 2) / min(f_kernel, f_channel)\n",
    "    #store block from local memory to global memory\n",
    "    t_total += (bsize * bsize / sbsize) / min(f_mem, f_kernel)\n",
    "    return t_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime for top, left block update in seconds\n",
    "def topleft_block(bsize, sbsize, f_kernel, f_channel=156e6, f_mem=300e6):\n",
    "    t_total = 0\n",
    "    #load block from global memory to local memory buffer\n",
    "    t_total += (bsize * bsize / sbsize) / min(f_mem, f_kernel)\n",
    "    # receive row from extern. Will be external channel bound in worst case and has a high latency because of the global memory access\n",
    "    t_total += (bsize * (bsize/sbsize + 240)) / min(f_kernel, f_channel, f_mem)\n",
    "    # total time needed to update all sub-blocks\n",
    "    t_total += (bsize * (bsize / sbsize) * bsize / sbsize / 2)/ f_kernel\n",
    "    #store block from local memory to global memory\n",
    "    t_total += (bsize * bsize / sbsize) / min(f_mem, f_kernel)\n",
    "    return t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime for inner block update in seconds\n",
    "def inner_block(bsize, sbsize, f_kernel, f_channel=156e6, f_mem=300e6):\n",
    "    t_total = 0\n",
    "    #load block from global memory to local memory buffer\n",
    "    t_total += (bsize * bsize / sbsize) / min(f_mem, f_kernel)\n",
    "    # receive row from extern. Will be external channel bound in worst case and has a high latency because of the global memory access\n",
    "    t_total += (bsize * (bsize/sbsize + 240)) / min(f_kernel, f_channel, f_mem)\n",
    "    # total time needed to update all sub-blocks\n",
    "    t_total += (bsize * (bsize / sbsize) * bsize / sbsize)/ f_kernel\n",
    "    #store block from local memory to global memory\n",
    "    t_total += (bsize * bsize / sbsize) / min(f_mem, f_kernel)\n",
    "    return t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime of the whole calculation for a matrix with multiple blocks in seconds\n",
    "def combined_single_fpga(size_in_blocks, f_kernel, bsize = 1024, f_mem=300e6):\n",
    "    t_total = 0\n",
    "    # for every block row\n",
    "    for brow in range(1,size_in_blocks):\n",
    "        # inner block update is bottleneck, everything else is pipelined, so just cound inner block time\n",
    "        t_total += (brow ** 2) * inner_block(bsize, 8, f_kernel, f_mem, f_mem)\n",
    "        # moreover, we have the first iteration of the LU update for every block row\n",
    "        #load block from global memory for LU is neglected because it is represented by the first execution of the inner update\n",
    "        # time needed to update all sub-blocks of the lu block for the first iteration\n",
    "        t_total += ((bsize / 8) ** 2)/ f_kernel\n",
    "    # at the end we need to do an additional lu block\n",
    "    t_total += lu_block(bsize,8,f_kernel, f_mem, f_mem)\n",
    "    return t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gflops_single_fpga(size_in_blocks, f_kernel, bsize):\n",
    "    return (2*(size_in_blocks * bsize)**3/3)/combined_single_fpga(size_in_blocks, f_kernel, bsize) * 1.0e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gflops_single_fpga(8,150e6, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for y in range(7,11):\n",
    "    plt.plot(list(range(16)), [gflops_single_fpga(x, 150e6, 2 ** y) for x in range(16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime for an additional inner update which uses matrix multiplication\n",
    "def inner_block_mm(bsize, sbsize, f_kernel, f_mem=300e6, load_stalls=0.0):\n",
    "    t_total = 0\n",
    "    #we need to load three blocks from global memory now\n",
    "    #because of memory interlaving this may happen simulataneously\n",
    "    t_total += (bsize * bsize / sbsize) / (min(f_mem, f_kernel) * (1.0 - load_stalls))\n",
    "    # total time needed to update all sub-blocks\n",
    "    t_total += ((bsize / sbsize) ** 3)/ f_kernel\n",
    "    # we still only need to store a single block\n",
    "    t_total += (bsize * bsize / sbsize) / min(f_mem, f_kernel)\n",
    "    return t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime of the whole calculation for a matrix with multiple blocks in seconds using also the additional inner update block\n",
    "def combined_single_fpga_mm(size_in_blocks, f_kernel, bsize = 1024, f_mem=300e6):\n",
    "    t_total = 0\n",
    "    # for every block row\n",
    "    for brow in range(1,size_in_blocks):\n",
    "        # inner block update is bottleneck, everything else is pipelined, so just count inner block time\n",
    "        # we execute the old inner block update only for the diagonal blocks\n",
    "        t_total += brow * inner_block(bsize, 8, f_kernel, f_mem, f_mem)\n",
    "        # all other blocks will be updated with the faster version\n",
    "        t_total += ((brow - 1) * brow) * inner_block_mm(bsize, 8, f_kernel, f_mem)\n",
    "        # moreover, we have the first iteration of the LU update for every block row\n",
    "        #load block from global memory for LU is neglected because it is represented by the first execution of the inner update\n",
    "        # time needed to update all sub-blocks of the lu block for the first iteration\n",
    "        t_total += ((bsize / 8) ** 2)/ f_kernel\n",
    "    # at the end we need to do an additional lu block\n",
    "    t_total += lu_block(bsize,8,f_kernel, f_mem, f_mem)\n",
    "    return t_total\n",
    "\n",
    "def gflops_single_fpga_mm(size_in_blocks, f_kernel, bsize):\n",
    "    return (2*(size_in_blocks * bsize)**3/3)/combined_single_fpga_mm(size_in_blocks, f_kernel, bsize) * 1.0e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Expected performance on single FPGA with kernel frequency 150MHz and block size 512\")\n",
    "plt.ylabel(\"GFLOP/s\")\n",
    "plt.xlabel(\"Matrix size\")\n",
    "plt.plot([ x  for x in range(0,32)], [gflops_single_fpga_mm(x, 300e6, 512) for x in range(0,32)], label=\"Approach using additional MM kernel\")\n",
    "plt.plot([ x  for x in range(0,32)], [gflops_single_fpga(x, 300e6, 512) for x in range(0,32)], label= \"Current approach\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Expected performance on single FPGA with kernel frequency 150MHz an MM kernel\")\n",
    "plt.ylabel(\"GFLOP/s\")\n",
    "plt.xlabel(\"Matrix size\")\n",
    "plt.plot([ x * 512 for x in range(0,16)], [gflops_single_fpga_mm(x, 150e6, 512) for x in range(0,16)], label=\"block 512\")\n",
    "plt.plot([ x * 256 for x in range(0,32)], [gflops_single_fpga_mm(x, 150e6, 256) for x in range(0,32)], label= \"block 256\")\n",
    "plt.plot([ x * 128 for x in range(0,64)], [gflops_single_fpga_mm(x, 150e6, 128) for x in range(0,64)], label= \"block 128\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gflops_single_fpga_mm(16, 219.45e6, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# runtime of the whole calculation for a matrix with multiple blocks in seconds using also the additional inner update block which can be replicated\n",
    "def combined_single_fpga_mm_multi(size_in_blocks, f_kernel, bsize = 1024,  mm_blocks=1, f_mem=300e6, load_stalls=0.0):\n",
    "    t_total = 0\n",
    "    # for every block row\n",
    "    for brow in range(1,size_in_blocks):\n",
    "        # inner block update is bottleneck, everything else is pipelined, so just count inner block time\n",
    "        # we execute the old inner block update only for the diagonal blocks\n",
    "        t_total += brow * inner_block(bsize, 8, f_kernel, f_mem, f_mem)\n",
    "        # all other blocks will be updated with the faster version\n",
    "        t_total += math.ceil(((brow - 1) * brow) / mm_blocks) * inner_block_mm(bsize, 8, f_kernel, f_mem, load_stalls)\n",
    "        # moreover, we have the first iteration of the LU update for every block row\n",
    "        #load block from global memory for LU is neglected because it is represented by the first execution of the inner update\n",
    "        # time needed to update all sub-blocks of the lu block for the first iteration\n",
    "        t_total += ((bsize / 8) ** 2)/ f_kernel\n",
    "    # at the end we need to do an additional lu block\n",
    "    t_total += lu_block(bsize,8,f_kernel, f_mem, f_mem)\n",
    "    return t_total\n",
    "\n",
    "def gflops_single_fpga_mm_multi(size_in_blocks, f_kernel, bsize, mm_blocks, load_stalls=0.0):\n",
    "    return (2*(size_in_blocks * bsize)**3/3)/combined_single_fpga_mm_multi(size_in_blocks, f_kernel, bsize, mm_blocks, load_stalls=load_stalls) * 1.0e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gflops_single_fpga_mm_multi(32, 219.45e6, 512,3))\n",
    "print(gflops_single_fpga_mm_multi(32, 219.45e6, 256,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Performance of 3 and 4 replications over the matrix size\")\n",
    "plt.xlabel(\"Matrix width in elements\")\n",
    "plt.ylabel(\"GFLOP/s\")\n",
    "plt.plot(list(range(512,512* 512, 512)), [gflops_single_fpga_mm_multi(x, 157.14e6, 512,3) for x in range(1,512)], label=\"3 replications\")\n",
    "plt.plot(list(range(512,512*512, 512)), [gflops_single_fpga_mm_multi(x, 116.67e6, 512,4) for x in range(1,512)], label=\"4 replications\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# create data frame out of measurements\n",
    "df_measurements = pd.DataFrame({ \"matrix_size\" : [512, 1024, 2048, 4096, 8192, 16384, 20480,22528, 24576, 32768, 87040],\n",
    "    \"initial\" : [11.09,32.16,56.68,92.23,141.45,198.47,214.97, 212.65, 202.10, 136.20, np.nan],\n",
    "    \"multi_queue\" : [np.nan,np.nan,np.nan,92.3,np.nan,np.nan,np.nan, 213.44, np.nan, 128.57, np.nan],\n",
    "    \"reduce_events\": [np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,216.32, 223.76, 212.05, 151.03, np.nan],\n",
    "    \"sliding_window\": [np.nan,np.nan,np.nan,92.20,np.nan,np.nan,216.58, np.nan, 230.58, 251.35, 302.91]})\n",
    "#df_measurements.set_index(\"matrix_size\", inplace=True)\n",
    "df_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.title(\"Compare performance of Synthesized Design to Model\")\n",
    "plt.xlabel(\"Matrix width in blocks of 512 elements\")\n",
    "plt.ylabel(\"GFLOP/s\")\n",
    "\n",
    "plt.plot(list(range(1,200)), [gflops_single_fpga_mm_multi(x, 157.14e6, 512,3) for x in range(1,200)], label=\"Model\")\n",
    "plt.plot(list(range(1,200)), [gflops_single_fpga_mm_multi(x, 157.14e6, 512,3, load_stalls=0.5) for x in range(1,200)], label=\"Model, load_stalls=50%\")\n",
    "plt.scatter(df_measurements[\"matrix_size\"] / 512, df_measurements[\"initial\"], label=\"Measurements\")\n",
    "plt.scatter(df_measurements[\"matrix_size\"]  / 512, df_measurements[\"multi_queue\"], label=\"Multi Queue Measurements\")\n",
    "plt.scatter(df_measurements[\"matrix_size\"]  / 512, df_measurements[\"reduce_events\"], label=\"Reduced Events Measurements\")\n",
    "plt.scatter(df_measurements[\"matrix_size\"]  / 512, df_measurements[\"sliding_window\"], label=\"JIT Release Measurements\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.xlim((0,180))\n",
    "#plt.ylim((0,350))\n",
    "plt.legend()\n",
    "#plt.savefig(\"measurement_anomaly4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gflops_single_fpga_mm_multi(40, 157.14e6, 512,3, load_stalls=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_block_mm(512,8,175e6, load_stalls=0.47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#58.21\n",
    "gflops_single_fpga_mm_multi(16, 175e6, 512,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}